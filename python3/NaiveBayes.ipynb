{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set():\n",
    "    postingList = [\n",
    "         ['my','dog','has','flea','problems','help','please']\n",
    "        ,['maybe','not','take','him','to','dog','park','stupid']\n",
    "        ,['my','dalmation','is','so','cute','I','love','him']\n",
    "        ,['stop','posting','stupid','worthless','garbage']\n",
    "        ,['mr','licks','ate','my','steak','how','to','stop','him']\n",
    "        ,['quit','buying','worthless','dog','food','stupid']\n",
    "        ]\n",
    "    classVec = [0, 1, 0, 1, 0, 1]\n",
    "    return postingList, classVec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document)\n",
    "#         print(vocabSet)\n",
    "    return list(vocabSet)\n",
    "\n",
    "def setOfWorks2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet :\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else :\n",
    "            print('The word: {} is not in my Vocabulary!'.format(word))\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     15
    ]
   },
   "outputs": [],
   "source": [
    "def classifyNB(vec_Classify, p0Vec, p1Vec,p1_class):\n",
    "    \n",
    "    p1 = np.dot(vec_Classify.T, p1Vec) + np.log(p1_class)\n",
    "    if p1 > 0.5 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def trainNB0(trainMatrix, trainLabels):\n",
    "    rows_train = len(trainMatrix)\n",
    "    cols_train = len(trainMatrix[0])\n",
    "    p1_Abusive   = sum(trainLabels)/float(rows_train)\n",
    "    \n",
    "    p0_num = np.ones(cols_train)\n",
    "    p1_num = np.ones(cols_train)\n",
    "    \n",
    "    p0_denom = 2.0\n",
    "    p1_denom = 2.0\n",
    "    \n",
    "    for i in range(rows_train):\n",
    "        if trainLabels[i] == 1:\n",
    "            p1_num    += trainMatrix[i]\n",
    "            p1_denom  += sum(trainMatrix[i])\n",
    "        else :\n",
    "            p0_num    += trainMatrix[i]\n",
    "            p0_denom  += sum(trainMatrix[i])\n",
    "    \n",
    "    #为了防止相乘后数值过小，用np.log（）取对数\n",
    "    p1_vector = np.log(p1_num/p1_denom)\n",
    "    p0_vector = np.log(p0_num/p1_denom)\n",
    "    \n",
    "    return p0_vector, p1_vector, p1_Abusive\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "listPosts,listClasses = load_data_set()\n",
    "myVocabList = createVocabList(listPosts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setOfWorks2Vec(myVocabList,listPosts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
